{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import requirements",
   "id": "c462e5e0b3160b12"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T17:29:09.850565Z",
     "start_time": "2024-11-08T17:29:09.847577Z"
    }
   },
   "source": [
    "import yaml, time, json, traceback\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "from pprint import PrettyPrinter\n",
    "from tabulate import tabulate\n",
    "import networkx as nx\n",
    "from itertools import count\n",
    "from fabrictestbed_extensions.fablib.fablib import fablib\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define a better printer for debugging process",
   "id": "386a258a7f81221e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:29:11.773222Z",
     "start_time": "2024-11-08T17:29:11.770313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pretty_print_defaultdict(d):\n",
    "    # Create PrettyPrinter instance with custom formatting\n",
    "    pp = PrettyPrinter(indent=4, width=80, sort_dicts=True)\n",
    "    \n",
    "    # Convert defaultdict to dict before printing\n",
    "    pp.pprint(dict(d))"
   ],
   "id": "3983dc08a25e574b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get values from YAML file",
   "id": "4f1f4080dcf60995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T15:56:01.040957Z",
     "start_time": "2024-11-08T15:56:01.035561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./config.yaml', 'r') as config_file:\n",
    "    base_config = yaml.safe_load(config_file)\n",
    "    \n",
    "client_node_names: List[str] = base_config['topology']['client_nodes']\n",
    "client_connections: Dict[str, List[str]] = base_config['topology']['client_connections']\n",
    "general_node_names: List[str] = base_config['topology']['nodes']\n",
    "general_connections: Dict[str, List[str]] = base_config['topology']['connections']\n",
    "\n",
    "all_nodes = client_node_names + general_node_names\n",
    "node_amount = len(all_nodes)\n",
    "\n",
    "print(f'Client node names: {client_node_names}')\n",
    "print(f'\\nClient connections: {json.dumps(client_connections, indent=2)}')\n",
    "print(f'\\nGeneral node names: {general_node_names}')\n",
    "print(f'\\nGeneral connections: {json.dumps(general_connections, indent=2)}')"
   ],
   "id": "4283def1241c06b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client node names: ['node1', 'node6', 'node11']\n",
      "\n",
      "Client connections: {\n",
      "  \"node1\": [\n",
      "    \"node2\"\n",
      "  ],\n",
      "  \"node6\": [\n",
      "    \"node7\"\n",
      "  ],\n",
      "  \"node11\": [\n",
      "    \"node12\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "General node names: ['node2', 'node3', 'node4', 'node5', 'node7', 'node8', 'node9', 'node10', 'node12', 'node13', 'node14', 'node15', 'node16', 'node17', 'node18', 'node19', 'node20']\n",
      "\n",
      "General connections: {\n",
      "  \"node2\": [\n",
      "    \"node3\",\n",
      "    \"node4\"\n",
      "  ],\n",
      "  \"node3\": [\n",
      "    \"node2\",\n",
      "    \"node5\",\n",
      "    \"node7\"\n",
      "  ],\n",
      "  \"node4\": [\n",
      "    \"node2\",\n",
      "    \"node8\",\n",
      "    \"node9\"\n",
      "  ],\n",
      "  \"node5\": [\n",
      "    \"node3\",\n",
      "    \"node10\"\n",
      "  ],\n",
      "  \"node7\": [\n",
      "    \"node3\",\n",
      "    \"node8\",\n",
      "    \"node13\"\n",
      "  ],\n",
      "  \"node8\": [\n",
      "    \"node4\",\n",
      "    \"node7\",\n",
      "    \"node14\"\n",
      "  ],\n",
      "  \"node9\": [\n",
      "    \"node4\",\n",
      "    \"node10\",\n",
      "    \"node15\"\n",
      "  ],\n",
      "  \"node10\": [\n",
      "    \"node5\",\n",
      "    \"node9\",\n",
      "    \"node16\"\n",
      "  ],\n",
      "  \"node12\": [\n",
      "    \"node13\",\n",
      "    \"node16\"\n",
      "  ],\n",
      "  \"node13\": [\n",
      "    \"node7\",\n",
      "    \"node12\",\n",
      "    \"node17\"\n",
      "  ],\n",
      "  \"node14\": [\n",
      "    \"node8\",\n",
      "    \"node15\",\n",
      "    \"node18\"\n",
      "  ],\n",
      "  \"node15\": [\n",
      "    \"node9\",\n",
      "    \"node14\",\n",
      "    \"node19\"\n",
      "  ],\n",
      "  \"node16\": [\n",
      "    \"node10\",\n",
      "    \"node12\",\n",
      "    \"node20\"\n",
      "  ],\n",
      "  \"node17\": [\n",
      "    \"node13\",\n",
      "    \"node18\"\n",
      "  ],\n",
      "  \"node18\": [\n",
      "    \"node14\",\n",
      "    \"node17\",\n",
      "    \"node19\"\n",
      "  ],\n",
      "  \"node19\": [\n",
      "    \"node15\",\n",
      "    \"node18\",\n",
      "    \"node20\"\n",
      "  ],\n",
      "  \"node20\": [\n",
      "    \"node16\",\n",
      "    \"node19\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define global variables",
   "id": "37c1c205cb02ab3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T15:56:14.763256Z",
     "start_time": "2024-11-08T15:56:14.649668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manager = fablib_manager()\n",
    "\n",
    "time_stamp = int(time.time())\n",
    "experiment_slice = fablib.new_slice(name=f\"hydra_auto_{time_stamp}\")\n",
    "\n",
    "# Basic node configs\n",
    "experiment_cores = 4\n",
    "experiment_ram = 8\n",
    "experiment_disk = 20\n",
    "experiment_image = \"default_ubuntu_20\"\n",
    "\n",
    "# In case of fail, pick manually\n",
    "def filter_sites(site):    \n",
    "    try:\n",
    "        if (site[\"state\"] == \"Active\" and \n",
    "            site[\"hosts\"] > 0 and \n",
    "            site[\"cores_available\"] >= experiment_cores * 2 and \n",
    "            site[\"ram_available\"] >= experiment_ram * 2 and \n",
    "            site[\"disk_available\"] >= experiment_disk * 2\n",
    "        ):\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as error:\n",
    "        print(f\"Filter error for site {site}: {error}\")\n",
    "        return False\n",
    "\n",
    "# Change amount of site based on the topology size\n",
    "experiment_sites = manager.get_random_sites(\n",
    "    count=4,\n",
    "    avoid=['NEWY'],\n",
    "    filter_function=filter_sites,\n",
    "    update=True,\n",
    "    unique=True \n",
    ")\n",
    "\n",
    "print(f'Available sites: {experiment_sites}')"
   ],
   "id": "e3822cb18c0d45ff",
   "outputs": [
    {
     "ename": "ConfigException",
     "evalue": "Token file does not exist, please provide the token at location: /Users/gportdev/.tokens.json!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConfigException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m time_stamp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime())\n\u001B[0;32m----> 2\u001B[0m experiment_slice \u001B[38;5;241m=\u001B[39m fablib\u001B[38;5;241m.\u001B[39mnew_slice(name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhydra_auto_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime_stamp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Change depending on the topology size\u001B[39;00m\n\u001B[1;32m      5\u001B[0m experiment_sites \u001B[38;5;241m=\u001B[39m fablib\u001B[38;5;241m.\u001B[39mget_random_sites(count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ndn-hydra/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:423\u001B[0m, in \u001B[0;36mfablib.new_slice\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_slice\u001B[39m(name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Slice:\n\u001B[1;32m    415\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;124;03m    Creates a new slice with the given name.\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;124;03m    :rtype: Slice\u001B[39;00m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 423\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fablib\u001B[38;5;241m.\u001B[39mget_default_fablib_manager()\u001B[38;5;241m.\u001B[39mnew_slice(name)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ndn-hydra/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:113\u001B[0m, in \u001B[0;36mfablib.get_default_fablib_manager\u001B[0;34m()\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_default_fablib_manager\u001B[39m():\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fablib\u001B[38;5;241m.\u001B[39mdefault_fablib_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 113\u001B[0m         fablib\u001B[38;5;241m.\u001B[39mdefault_fablib_manager \u001B[38;5;241m=\u001B[39m FablibManager()\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fablib\u001B[38;5;241m.\u001B[39mdefault_fablib_manager\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ndn-hydra/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:654\u001B[0m, in \u001B[0;36mFablibManager.__init__\u001B[0;34m(self, fabric_rc, credmgr_host, orchestrator_host, core_api_host, token_location, project_id, bastion_username, bastion_key_location, log_level, log_file, data_dir, output, execute_thread_pool_size, offline, auto_token_refresh, **kwargs)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    588\u001B[0m     fabric_rc: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    604\u001B[0m ):\n\u001B[1;32m    605\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m    ``FablibManager`` is the main interface to FABRIC services.\u001B[39;00m\n\u001B[1;32m    607\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;124;03m    :param auto_token_refresh: Auto refresh tokens\u001B[39;00m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 654\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    655\u001B[0m         fabric_rc\u001B[38;5;241m=\u001B[39mfabric_rc,\n\u001B[1;32m    656\u001B[0m         credmgr_host\u001B[38;5;241m=\u001B[39mcredmgr_host,\n\u001B[1;32m    657\u001B[0m         orchestrator_host\u001B[38;5;241m=\u001B[39morchestrator_host,\n\u001B[1;32m    658\u001B[0m         core_api_host\u001B[38;5;241m=\u001B[39mcore_api_host,\n\u001B[1;32m    659\u001B[0m         token_location\u001B[38;5;241m=\u001B[39mtoken_location,\n\u001B[1;32m    660\u001B[0m         project_id\u001B[38;5;241m=\u001B[39mproject_id,\n\u001B[1;32m    661\u001B[0m         bastion_username\u001B[38;5;241m=\u001B[39mbastion_username,\n\u001B[1;32m    662\u001B[0m         bastion_key_location\u001B[38;5;241m=\u001B[39mbastion_key_location,\n\u001B[1;32m    663\u001B[0m         log_level\u001B[38;5;241m=\u001B[39mlog_level,\n\u001B[1;32m    664\u001B[0m         log_file\u001B[38;5;241m=\u001B[39mlog_file,\n\u001B[1;32m    665\u001B[0m         data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[1;32m    666\u001B[0m         offline\u001B[38;5;241m=\u001B[39moffline,\n\u001B[1;32m    667\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    668\u001B[0m     )\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    671\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m output\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ndn-hydra/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/config/config.py:218\u001B[0m, in \u001B[0;36mConfig.__init__\u001B[0;34m(self, fabric_rc, credmgr_host, orchestrator_host, core_api_host, token_location, project_id, bastion_username, bastion_key_location, log_level, log_file, data_dir, offline, **kwargs)\u001B[0m\n\u001B[1;32m    216\u001B[0m token_location \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_token_location()\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(token_location):\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConfigException(\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToken file does not exist, please provide the token at location: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtoken_location\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    220\u001B[0m     )\n",
      "\u001B[0;31mConfigException\u001B[0m: Token file does not exist, please provide the token at location: /Users/gportdev/.tokens.json!"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add nodes and interfaces",
   "id": "895e270bab0496d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:34:27.766824Z",
     "start_time": "2024-11-08T16:34:27.760184Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processing client node1\n",
      "Fail: name 'experiment_slice' is not defined\n"
     ]
    }
   ],
   "execution_count": 15,
   "source": [
    "site_selector = count()\n",
    "\n",
    "nodes = defaultdict(dict)\n",
    "nodes_interfaces = defaultdict(list)\n",
    "client_nodes = defaultdict(dict)\n",
    "client_interfaces = defaultdict(list)\n",
    "networks = defaultdict(list)\n",
    "\n",
    "# Helper function to count total connections for a node\n",
    "def count_total_connections(node_name):\n",
    "    # For client nodes, just count their outgoing connections\n",
    "    if node_name in client_node_names:\n",
    "        return len(client_connections.get(node_name, []))\n",
    "    \n",
    "    # For general nodes, count unique connections\n",
    "    connections = set()\n",
    "    \n",
    "    # Add outgoing connections\n",
    "    for target in general_connections.get(node_name, []):\n",
    "        connections.add(tuple(sorted([node_name, target])))\n",
    "    \n",
    "    # Add incoming connections\n",
    "    for source, targets in general_connections.items():\n",
    "        if node_name in targets:\n",
    "            connections.add(tuple(sorted([source, node_name])))\n",
    "    \n",
    "    # Add connections from clients\n",
    "    for client, targets in client_connections.items():\n",
    "        if node_name in targets:\n",
    "            connections.add(tuple(sorted([client, node_name])))\n",
    "            \n",
    "    return len(connections)\n",
    "\n",
    "try:\n",
    "    # Add each client node to the slice\n",
    "    for node_name in client_node_names:\n",
    "        print(f'> Processing client {node_name}')\n",
    "        current_node = experiment_slice.add_node(\n",
    "            name=node_name,\n",
    "            site=experiment_sites[next(site_selector) % len(experiment_sites)],\n",
    "            cores=experiment_cores,\n",
    "            ram=experiment_ram,\n",
    "            disk=experiment_disk,\n",
    "            image=experiment_image\n",
    "        ) \n",
    "        \n",
    "        # Calculate total needed interfaces for this client\n",
    "        total_interfaces = count_total_connections(node_name)\n",
    "        print(f'> {node_name} needs {total_interfaces} interfaces')\n",
    "        \n",
    "        # Add all needed interfaces to the node\n",
    "        for i in range(total_interfaces):\n",
    "            print(f'> \\tAdding interface {i+1} to client {node_name}')\n",
    "            new_connection = current_node.add_component(\n",
    "                model='NIC_Basic', \n",
    "                name=f'nic-{node_name[-1]}-{i+1}'\n",
    "            ).get_interfaces()[0]\n",
    "            \n",
    "            client_interfaces[node_name].append(new_connection)\n",
    "        \n",
    "        client_nodes[node_name] = current_node\n",
    "        \n",
    "    # Add each general node to the slice\n",
    "    for node_name in general_node_names:\n",
    "        print(f'> Processing {node_name}')\n",
    "        \n",
    "        current_node = experiment_slice.add_node(\n",
    "            name=node_name,\n",
    "            site=experiment_sites[next(site_selector) % len(experiment_sites)],\n",
    "            cores=experiment_cores,\n",
    "            ram=experiment_ram,\n",
    "            disk=experiment_disk,\n",
    "            image=experiment_image\n",
    "        )\n",
    "        \n",
    "        # Calculate total needed interfaces for this node\n",
    "        total_interfaces = count_total_connections(node_name)\n",
    "        print(f'> {node_name} needs {total_interfaces} interfaces')\n",
    "        \n",
    "        # Add all needed interfaces to the node\n",
    "        for i in range(total_interfaces):\n",
    "            print(f'> \\tAdding interface {i+1} to {node_name}')\n",
    "            new_connection = current_node.add_component(\n",
    "                model='NIC_Basic',\n",
    "                name=f'nic-{node_name[-1]}-{i+1}'\n",
    "            ).get_interfaces()[0]\n",
    "            \n",
    "            nodes_interfaces[node_name].append(new_connection)\n",
    "            \n",
    "        nodes[node_name] = current_node\n",
    "\n",
    "    # Debug output\n",
    "    print(\"\\nInterface counts per node:\")\n",
    "    for node_name in client_nodes:\n",
    "        print(f\"{node_name}: {len(client_interfaces[node_name])} interfaces\")\n",
    "    for node_name in nodes:\n",
    "        print(f\"{node_name}: {len(nodes_interfaces[node_name])} interfaces\")\n",
    "    \n",
    "    print(\"\\nConnection counts per node:\")\n",
    "    for node_name in {**client_nodes, **nodes}:\n",
    "        print(f\"{node_name}: {count_total_connections(node_name)} connections\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"> Node configuration failed: \\n{e}\")\n",
    "    traceback.print_exc(e)"
   ],
   "id": "703c398d80b278bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add Networks",
   "id": "4f693d7dbd042b03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create copies of interface tables\n",
    "client_interfaces_copy = {k: v[:] for k, v in client_interfaces.items()}\n",
    "nodes_interfaces_copy = {k: v[:] for k, v in nodes_interfaces.items()}\n",
    "\n",
    "# Helper function to check if nodes are already connected\n",
    "def are_nodes_connected(node1, node2, networks):\n",
    "    return any(\n",
    "        f'net-{n1}-{n2}' in networks.get(node1, [])\n",
    "        for n1 in [node1[-1], node2[-1]]\n",
    "        for n2 in [node1[-1], node2[-1]]\n",
    "    )\n",
    "\n",
    "# Helper function to create network connection\n",
    "def create_network_connection(source_node, target_node, source_interface, target_interface, networks):\n",
    "    network_name = f'net-{source_node[-1]}-{target_node[-1]}'\n",
    "    \n",
    "    # Create L2 network\n",
    "    experiment_slice.add_l2network(\n",
    "        name=network_name,\n",
    "        interfaces=[source_interface, target_interface]\n",
    "    )\n",
    "    \n",
    "    # Record network connection\n",
    "    networks[source_node].append(network_name)\n",
    "    networks[target_node].append(network_name)\n",
    "\n",
    "try:\n",
    "    # --- Add networks for clients\n",
    "    for node_name in client_node_names:\n",
    "        for connection in client_connections[node_name]:\n",
    "            # Check if these nodes are not already connected\n",
    "            if not are_nodes_connected(node_name, connection, networks):\n",
    "                \n",
    "                # Check if interfaces are available for both nodes\n",
    "                if (node_name in client_interfaces_copy and client_interfaces_copy[node_name] and\n",
    "                    connection in nodes_interfaces_copy and nodes_interfaces_copy[connection]):\n",
    "                    \n",
    "                    # Get interfaces for the connection\n",
    "                    source_interface = client_interfaces_copy[node_name][0]\n",
    "                    target_interface = nodes_interfaces_copy[connection][0]\n",
    "                    \n",
    "                    create_network_connection(\n",
    "                        node_name, connection, \n",
    "                        source_interface, target_interface, \n",
    "                        networks\n",
    "                    )\n",
    "                    \n",
    "                    # Remove used interfaces from copies\n",
    "                    client_interfaces_copy[node_name].remove(source_interface)\n",
    "                    nodes_interfaces_copy[connection].remove(target_interface)\n",
    "\n",
    "    # --- Add networks for general nodes\n",
    "    # Process all connections from general_connections\n",
    "    processed_pairs = set()\n",
    "    \n",
    "    for source_node, target_nodes in general_connections.items():\n",
    "        for target_node in target_nodes:\n",
    "            # Create a sorted pair to avoid duplicates\n",
    "            node_pair = tuple(sorted([source_node, target_node]))\n",
    "            \n",
    "            # Skip if this pair has been processed\n",
    "            if node_pair in processed_pairs:\n",
    "                continue\n",
    "                \n",
    "            # Check if these nodes are not already connected\n",
    "            if not are_nodes_connected(source_node, target_node, networks):\n",
    "                \n",
    "                # Check if interfaces are available for both nodes\n",
    "                if (source_node in nodes_interfaces_copy and nodes_interfaces_copy[source_node] and\n",
    "                    target_node in nodes_interfaces_copy and nodes_interfaces_copy[target_node]):\n",
    "                    \n",
    "                    # Get interfaces for the connection\n",
    "                    source_interface = nodes_interfaces_copy[source_node][0]\n",
    "                    target_interface = nodes_interfaces_copy[target_node][0]\n",
    "                    \n",
    "                    create_network_connection(\n",
    "                        source_node, target_node, \n",
    "                        source_interface, target_interface, \n",
    "                        networks\n",
    "                    )\n",
    "                    \n",
    "                    # Remove used interfaces from copies\n",
    "                    nodes_interfaces_copy[source_node].remove(source_interface)\n",
    "                    nodes_interfaces_copy[target_node].remove(target_interface)\n",
    "            \n",
    "            # Mark this pair as processed\n",
    "            processed_pairs.add(node_pair)\n",
    "\n",
    "except Exception as e:\n",
    "    traceback.print_exc(e)\n",
    "\n",
    "# Print debug information\n",
    "print(\"Final networks:\", dict(networks))\n",
    "print(\"Remaining interfaces for nodes:\", dict(nodes_interfaces_copy))\n",
    "print(\"Remaining interfaces for clients:\", dict(client_interfaces_copy))"
   ],
   "id": "dc9fcfee2c6c2c1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Print information about nodes and connections",
   "id": "a91f8c2979b6232f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'Nodes above. {pretty_print_defaultdict(nodes)}\\n')\n",
    "print(f'Nodes interfaces above. {pretty_print_defaultdict(nodes_interfaces)}\\n')\n",
    "print(f'Client nodes above. {pretty_print_defaultdict(client_nodes)}\\n')\n",
    "print(f'Client nodes interfaces above. {pretty_print_defaultdict(client_interfaces)}\\n')\n",
    "print(f'Networks above. {pretty_print_defaultdict(networks)}\\n')"
   ],
   "id": "1abde8a5ce179978"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Submit slice (Wait until Stable)",
   "id": "2cf1f352a0b5d417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a checkpoint and only execute the rest of the code if the slice is stable\n",
    "try:\n",
    "    experiment_slice.submit()\n",
    "except Exception as e:\n",
    "    print(f\"Slice submission error: {e}\")"
   ],
   "id": "60026e1df70f7d85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Hydra dependencies in each node",
   "id": "238bb3b7f15773b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# For each node, install all the dependencies\n",
    "\n",
    "try:\n",
    "    for node in experiment_slice.get_nodes():\n",
    "        stdout, stderr = node.execute('sudo apt update && sudo apt upgrade -y')\n",
    "        stdout, stderr = node.execute('sudo apt install software-properties-common')\n",
    "        stdout, stderr = node.execute('sudo add-apt-repository ppa:named-data/ppa')              \n",
    "        stdout, stderr = node.execute('sudo apt update')\n",
    "        stdout, stderr = node.execute('sudo apt install nfd')\n",
    "        stdout, stderr = node.execute('sudo apt -y install python3-pip libndn-cxx-dev ndnping ndnpeek ndn-dissect ndnchunks ndnsec')\n",
    "        stdout, stderr = node.execute('pip3 install packing')\n",
    "        stdout, stderr = node.execute('git clone https://github.com/tntech-ngin/ndn-hydra.git')\n",
    "        stdout, stderr = node.execute('cd ndn-hydra/ && pip install -e .')\n",
    "        stdout, stderr = node.execute('pip3 install python-ndn ndn-storage ndn-svs numpy')\n",
    "        stdout, stderr = node.execute('sudo apt install net-tools')\n",
    "        stdout, stderr = node.execute('sudo cp /etc/ndn/nfd.conf.sample /etc/ndn/nfd.conf')\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ],
   "id": "64153728c4d3bdd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NFD environment configuration for each node",
   "id": "891c789298810a2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Bring up the interfaces\n",
    "\n",
    "for node in experiment_slice.get_nodes():\n",
    "    for interface in node.get_interfaces():\n",
    "        stdout, stderr = node.execute(f'sudo ip link set dev {interface.get_device_name()} up')\n",
    "        stdout, stderr = node.execute('sleep 2; ip a')\n",
    "\n",
    "for i, node_name in enumerate(client_node_names):\n",
    "    node = experiment_slice.get_node(node_name)\n",
    "    stdout, stderr = node.execute('nfd-stop')\n",
    "    stdout, stderr = node.execute('nfd-start')\n",
    "    stdout, stderr = node.execute('sleep 2; nfd-status')\n",
    "    stdout, stderr = node.execute(f'ndnsec key-gen /client{i} | ndnsec cert-install -')\n",
    "    \n",
    "for i, node_name in enumerate(general_node_names):\n",
    "    node = experiment_slice.get_node(node_name)\n",
    "    stdout, stderr = node.execute('nfd-stop')\n",
    "    stdout, stderr = node.execute('nfd-start')\n",
    "    stdout, stderr = node.execute('sleep 2; nfd-status')\n",
    "    stdout, stderr = node.execute(f'ndnsec key-gen /hydra/{node_name} | ndnsec cert-install -')"
   ],
   "id": "f777a737a2fa8c5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configure NFD faces and routes",
   "id": "9211dffa3de0b186"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client_interfaces_copy = defaultdict(list)\n",
    "\n",
    "for client_node_name in client_node_names:\n",
    "    client_node = experiment_slice.get_node(client_node_name)\n",
    "    for interface in client_node.get_interfaces():\n",
    "        client_interfaces_copy[client_node_name].append(interface)\n",
    "        \n",
    "nodes_interfaces_copy = defaultdict(list)\n",
    "for node_name in nodes_interfaces_copy:\n",
    "    node = experiment_slice.get_node(node_name)\n",
    "    for interface in node.get_interfaces():\n",
    "        nodes_interfaces_copy[node_name].append(interface)\n",
    "\n",
    "nfd_connections = defaultdict(list)\n",
    "\n",
    "def are_nodes_nfd_connected(source_node: str, target_node: str, all_nfd_connections: dict[str, list[str]]):\n",
    "    return target_node in all_nfd_connections.get(source_node, [])\n",
    "\n",
    "try:      \n",
    "    for client_node_name in client_node_names:\n",
    "        for connection in client_connections[client_node_name]:\n",
    "            source_node = nodes_interfaces_copy[client_node_name]\n",
    "            \n",
    "            # Check if these nodes are not already connected\n",
    "            if not are_nodes_nfd_connected(client_node_name, connection, nfd_connections):\n",
    "                print(f'NFD Connecting {client_node_name} to {connection}...')\n",
    "                \n",
    "                # Check if interfaces are available for both nodes\n",
    "                if (client_node_name in client_interfaces_copy and \n",
    "                        client_interfaces_copy[client_node_name] and \n",
    "                        connection in nodes_interfaces_copy and nodes_interfaces_copy[connection]):\n",
    "                            \n",
    "                    # Get interfaces for the connection\n",
    "                    source_node_interface = client_interfaces_copy[client_node_name][0]\n",
    "                    target_node_interface = nodes_interfaces_copy[connection][0]\n",
    "                    \n",
    "                    print(f'Source node interface: {source_node_interface}')\n",
    "                    print(f'Target node interface: {target_node_interface}')\n",
    "                    \n",
    "                    source_interface_mac_address, local_nic_name = \"ether://[\" + source_node_interface.get_mac() + \"]\", \"dev://\" + target_node_interface.get_device_name()\n",
    "            \n",
    "                    stdout, stderr = source_node.execute(f'nfdc face create remote {source_interface_mac_address} local {local_nic_name}')\n",
    "                    stdout, stderr = source_node.execute(f'nfdc route add / {source_interface_mac_address}')\n",
    "                    stdout, stderr = source_node.execute(f'nfdc cs config capacity 0 admit off serve off')\n",
    "                    \n",
    "                    # Remove used interfaces from copies\n",
    "                    client_interfaces_copy[client_node_name].remove(source_node_interface)\n",
    "                    nodes_interfaces_copy[connection].remove(target_node_interface)\n",
    "                    \n",
    "except Exception as e:\n",
    "    traceback.print_exc(e)\n",
    "            \n",
    "processed_nfd_pairs = set()\n",
    "try:\n",
    "    for source_node_name, target_nodes in general_connections.items():\n",
    "        for target_node_name in target_nodes:\n",
    "            print(f'NFD Connecting {source_node_name} to {target_node_name}...')\n",
    "            \n",
    "            # Create a sorted pair to avoid duplicates\n",
    "            node_pair = tuple(sorted([source_node_name, target_node_name]))\n",
    "            \n",
    "            # Skip if this pair has been processed\n",
    "            if node_pair in processed_nfd_pairs:\n",
    "                continue\n",
    "                \n",
    "            # Check if these nodes are not already connected\n",
    "            if not are_nodes_nfd_connected(source_node_name, target_node_name, nfd_connections):\n",
    "                source_node = nodes_interfaces_copy[source_node_name]\n",
    "               \n",
    "                # Check if interfaces are available for both nodes\n",
    "                if (source_node_name in nodes_interfaces_copy and nodes_interfaces_copy[source_node_name] and\n",
    "                            target_node_name in nodes_interfaces_copy and nodes_interfaces_copy[target_node_name]):\n",
    "                    \n",
    "                    source_node_interface = nodes_interfaces_copy[source_node_name][0]\n",
    "                    target_node_interface = nodes_interfaces_copy[target_node_name][0]\n",
    "                    \n",
    "                    print(f'Source node interface: {source_node_interface}')\n",
    "                    print(f'Target node interface: {target_node_interface}')\n",
    "                    \n",
    "                    # Perform connections\n",
    "                    stdout, stderr = source_node.execute('nfdc strategy set /hydra/group /localhost/nfd/strategy/multicast')\n",
    "                    \n",
    "                    remote_mac_address, local_nic_name = \"ether://[\" + source_node_interface.get_mac() + \"]\", \"dev://\" + target_node_interface.get_device_name()\n",
    "                    \n",
    "                    stdout, stderr = source_node.execute(f'nfdc face create remote {remote_mac_address} local {local_nic_name}')\n",
    "                    stdout, stderr = source_node.execute(f'nfdc route add /hydra/{target_node_name} {remote_mac_address}')\n",
    "                    stdout, stderr = source_node.execute(f'nfdc route add /{target_node_name} {remote_mac_address}')\n",
    "                    stdout, stderr = source_node.execute(f'nfdc route add /hydra/group {remote_mac_address}')\n",
    "                    \n",
    "                    # Disable cache\n",
    "                    stdout, stderr = source_node.execute(f'nfdc cs config capacity 0 admit off serve off')\n",
    "                    \n",
    "                    # Remove used interfaces from copies\n",
    "                    nodes_interfaces_copy[source_node_name].remove(source_node_interface)\n",
    "                    nodes_interfaces_copy[target_node_name].remove(target_node_interface)    \n",
    "                    \n",
    "                # Mark this pair as processed\n",
    "                processed_nfd_pairs.add(node_pair)\n",
    "\n",
    "except Exception as e:\n",
    "    traceback.print_exc(e)\n",
    "\n",
    "print(processed_nfd_pairs)"
   ],
   "id": "6b9c7ae501d2cceb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
